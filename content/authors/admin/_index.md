---
authors:
- admin
bio: My research interests include Natural Language Processing, Cognitive Science, and Deep Learning.
#education:
#  courses:
#  - course: PhD, Natural Language Understanding
#    institution: Purdue University
#    year: Current
#  - course: MS in Computer Information Technology
#    institution: Purdue University
#    year: 2020
#  - course: BS in Computer Information Technology
#    institution: Purdue University
#    year: 2018
email: ""

# 
# interests:
# - Inductive Reasoning
# - Concepts and Categories
# - Language Understanding
# - Lexical Semantics
# - Typicality and Vagueness

organizations:
#- name: AKRaNLU Lab
#  url: "https://engineering.purdue.edu/akranlu"
#- name: UChicago CompLing Lab
#  url: "https://uchicagocompling.github.io/"
#- name: Purdue University
#  url: "https://www.purdue.edu/"
# - name: Speech & Language @ TTIC
#   url: "https://home.ttic.edu/~klivescu/SLATTIC/people.htm"
- name: UT Austin CompLing Group
  url: "https://sites.utexas.edu/compling/"
- name: UT Austin NLP
  url: "https://www.nlp.utexas.edu/"
# role: Postdoc at UT Austin
role: Assistant Professor of Linguistics and Harrington Fellow at UT-Austin
social:
- icon: x-twitter
  icon_pack: fab
  link: https://twitter.com/kanishkamisra
- icon: bluesky
  icon_pack: fab
  link: https://bsky.app/profile/kanishka.bsky.social
- icon: google-scholar
  icon_pack: ai
  link: https://scholar.google.com/citations?user=-c6SAOMAAAAJ&hl=en
- icon: github
  icon_pack: fab
  link: https://github.com/kanishkamisra
#- icon: researchgate
#  icon_pack: ai
#  link: https://www.researchgate.net/profile/Kanishka_Misra
- icon: semantic-scholar
  icon_pack: ai
  link: https://www.semanticscholar.org/author/Kanishka-Misra/145274478
- icon: linkedin-in
  icon_pack: fab
  link: https://www.linkedin.com/in/kanishkamisra/
superuser: true
title: Kanishka Misra
user_groups:
- Researchers
- Visitors
---

<!--I am a postdoctoral fellow in the linguistics department at UT Austin, working with [Dr. Kyle Mahowald](https://mahowak.github.io/). In Sept 2024, I will start as a Research Assistant Professor at the [Toyota Technological Institute at Chicago](https://www.ttic.edu/)! -->

I am an Assistant Professor in the [Linguistics Department at UT Austin](https://liberalarts.utexas.edu/linguistics/), and 
a [Harrington Faculty Fellow](https://harrington.utexas.edu/faculty-fellows-program) for 2025-26. 
I am a member of the [Computational Linguistics Research Group](https://sites.utexas.edu/compling/) and 
also the [wider NLP Research Community at UT](https://www.nlp.utexas.edu/). I maintain a courtesy appointment at Toyota Technological Institute at Chicago.

<!--My research focuses on evaluating and analyzing large language models from the perspective of human semantic cognition, investigating capacities such as their ability to encode [typicality effects](https://arxiv.org/abs/2105.02987), [recall property knowledge](https://arxiv.org/abs/2205.06910), demonstrate [property inheritance](https://arxiv.org/abs/2210.01963), and perform human-like [category-based induction](https://arxiv.org/abs/2205.06910). Together, these capacities shed light on the extent to which LMs encode and extract conceptual meaning from input contexts. Through my work, I hope to contribute towards bridging the experimental paradigms in the study of human cognition with that of artificial intelligence systems.-->
My research program lies at the intersection of Cognitive Science, Linguistics, and Artificial Intelligence. I am primarily interested in characterizing the statistical mechanisms that underlie the acquisition and generalization of complex linguistic phenomena and conceptual meaning. To this end, I: (1) develop methods to evaluate and analyze AI models from the perspective of semantic cognition; and (2) use AI models as simulated learners to test and generate novel hypotheses about language acquisition and generalization. My research has been recognized with awards at [EACL 2023](https://2023.eacl.org/program/best-paper/), [ACL 2023](https://2023.aclweb.org/program/best_papers/), and [EMNLP 2024](https://2024.emnlp.org/program/best_papers/)!

<!--**Recruitment Note:** I am looking to recruit PhD Students through Linguistics, expected to start in Fall 2026. I am primarily interested in working with students who have interests at the intersection of AI <u>and</u> CogSci/NLP. Unfortunately, I am not recruiting any MS Students or Interns at the moment.-->
{{% alert note %}}
I am looking to recruit PhD Students through Linguistics, expected to start in Fall 2026. 
I am primarily interested in working with students who have interests at the intersection 
of AI <u>and</u> CogSci/NLP. Students can learn more about applications [here](https://liberalarts.utexas.edu/linguistics/graduate-programs/how-to-apply.html). 

Unfortunately, I am not recruiting any MS Students or Interns at the moment.
{{% /alert %}}

Previously, I was a Research Assistant Professor at the [Toyota Technological Institute at Chicago](https://www.ttic.edu/), a philanthropically endowed academic computer science institute located on the University of Chicago campus. Before, I was a postdoctoral fellow in the Linguistics department at UT Austin, working with [Dr. Kyle Mahowald](https://mahowak.github.io/). Before that, I was a PhD student at Purdue University, where I worked on Natural Language Understanding with [Dr. Julia Taylor Rayz](https://polytechnic.purdue.edu/profile/taylo108) at the [AKRaNLU Lab](https://engineering.purdue.edu/AKRANLU/). I also worked closely with [Dr. Allyson Ettinger](https://aetting.github.io/) and her [lab](https://uchicagocompling.github.io/) at UChicago.

My email is kanishka \[at\] ttic \[dot\] edu.<sup><a href = "https://en.wikipedia.org/wiki/Address_munging">\[why is it like that?\]</a></sup>

<!--**Note:** I am not currently looking to hire any PhD students, but please reach out to me if I can be of assistance or point you to other fantastic researchers who are looking for students. I will unfortunately not respond to your email if its content suggests you have not read my website.-->
<!--I am particularly interested in characterizing the semantic knowledge made available to computational models that only learn from textual exposure. I work closely with [Dr. Allyson Ettinger](https://aetting.github.io/) and her lab at UChicago. 
<!--I am also affiliated with [CERIAS](https://www.cerias.purdue.edu/), Purdue's center for research and education in areas of information security.-->

### Other things:

-   I co-organized the UChicago/TTIC NLP Seminar, along with the wonderful [Mina Lee](https://minalee-research.github.io/) and [Zhewei Sun](https://zhewei-sun.github.io/).
-   I am the author of [minicons](https://minicons.kanishka.website), a python package that facilitates large scale behavioral analyses of transformer language models.
-   I spent Fall 2022 as a Research Intern at Google AI working on multi-hop reasoning and language models.
-   In summer of 2022, I hosted a two part discussion group on [Neural Nets for Cognition](https://neural-nets-for-cognition.net/) \@ [CogSci 2022](https://cognitivesciencesociety.org/cogsci-2022/)
<!---   I was selected to be a Graduate Student Fellow in the inaugural [Purdue Graduate School Mentoring Fellows](https://news.cla.purdue.edu/2021/12/01/purdues-graduate-school-mentoring-graduate-student-fellow-program/) program!-->
<!--In 2018, I was fortunate to be awarded the Purdue Research Foundation fellowship (now known as the Ross-Lynn Graduate Student Fellowship). I then taught database fundamentals to sophomore level undergraduates for three semesters. I am currently funded by an [NSF-EAGER grant](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2039605&HistoricalAwards=false) focused on using artificial intelligence techniques to develop entertainment education materials for social-engineering research.-->
<!--I enjoy mentoring students interested in Natural Language Processing, check out my CV for some examples of undergraduate projects I have mentored.--->
<!---{{% alert note %}}
I am currently working on projects .
{{% /alert %}}--->

## Representative Papers

- **Kanishka Misra**, Julia Rayz, and Allyson Ettinger. 2023. [COMPS: Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models](https://aclanthology.org/2023.eacl-main.213/). *EACL 2023*. **Best Paper Award**.

- **Kanishka Misra** and Kyle Mahowald. 2024. [Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs](https://aclanthology.org/2024.emnlp-main.53/). *EMNLP 2024*. **Outstanding Paper Award**.

- **Kanishka Misra** and Najoung Kim. 2024. [Generating novel experimental hypotheses from language models: A case study on cross-dative generalization](https://arxiv.org/abs/2408.05086). *arxiv preprint*.

- Juan Diego Rodriguez, Aaron Mueller, and **Kanishka Misra**. 2025. 
[Characterizing the Role of Similarity in the Property Inferences of Language Models](https://aclanthology.org/2025.naacl-long.574/). *NAACL 2025*.

- Yulu Qin,<sup>\*</sup> Dheeraj Varghese,<sup>\*</sup> Adam Dahlgren Lindstr√∂m, Lucia Donatelli, **Kanishka Misra**,<sup>&dagger;</sup> and Najoung Kim.<sup>&dagger;</sup> 2025. 
[Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328). *arxiv preprint, Under Review*.

<!--**Contribution of language to semantic cognition**
- Typicality effects
- Property Induction
- COMPS
- FS COMPS
- Juan Diego Paper

**Understanding the role of Input in learning Generalizations**-->


